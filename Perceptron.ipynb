{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67181221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7273973822593689\n",
      "1000 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "# 단층 퍼셉트론으로 XOR 문제 해결하기\n",
    "## XOR 문제는 선형 분리가 불가능하여 단층 퍼셉트론으로는 해결할 수 없음\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    \n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
    "\n",
    "linear = nn.Linear(2, 1, bias=True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "model = nn.Sequential(linear, sigmoid).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2286ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6948983669281006\n",
      "100 0.693155825138092\n",
      "200 0.6931535005569458\n",
      "300 0.6931513547897339\n",
      "400 0.6931493282318115\n",
      "500 0.6931473016738892\n",
      "600 0.6931453943252563\n",
      "700 0.6931434869766235\n",
      "800 0.6931416988372803\n",
      "900 0.6931397914886475\n",
      "1000 0.6931380033493042\n",
      "1100 0.6931361556053162\n",
      "1200 0.6931343078613281\n",
      "1300 0.6931324005126953\n",
      "1400 0.6931304931640625\n",
      "1500 0.6931284666061401\n",
      "1600 0.6931264400482178\n",
      "1700 0.6931242942810059\n",
      "1800 0.6931220293045044\n",
      "1900 0.6931197047233582\n",
      "2000 0.6931172609329224\n",
      "2100 0.6931145191192627\n",
      "2200 0.6931115984916687\n",
      "2300 0.6931084990501404\n",
      "2400 0.6931051015853882\n",
      "2500 0.6931014657020569\n",
      "2600 0.6930974721908569\n",
      "2700 0.6930930018424988\n",
      "2800 0.6930879950523376\n",
      "2900 0.6930825114250183\n",
      "3000 0.6930763721466064\n",
      "3100 0.6930692791938782\n",
      "3200 0.6930612325668335\n",
      "3300 0.6930519342422485\n",
      "3400 0.6930410861968994\n",
      "3500 0.6930283904075623\n",
      "3600 0.6930133700370789\n",
      "3700 0.6929950714111328\n",
      "3800 0.6929728984832764\n",
      "3900 0.6929453015327454\n",
      "4000 0.6929103136062622\n",
      "4100 0.6928649544715881\n",
      "4200 0.6928046941757202\n",
      "4300 0.6927220225334167\n",
      "4400 0.692604124546051\n",
      "4500 0.6924278736114502\n",
      "4600 0.692147970199585\n",
      "4700 0.6916664838790894\n",
      "4800 0.690739631652832\n",
      "4900 0.6886204481124878\n",
      "5000 0.6820822954177856\n",
      "5100 0.64725661277771\n",
      "5200 0.45006048679351807\n",
      "5300 0.04144400730729103\n",
      "5400 0.009740812703967094\n",
      "5500 0.0050367750227451324\n",
      "5600 0.0032976851798594\n",
      "5700 0.0024171648547053337\n",
      "5800 0.0018924714531749487\n",
      "5900 0.001546937506645918\n",
      "6000 0.0013034611474722624\n",
      "6100 0.0011233121622353792\n",
      "6200 0.000984968151897192\n",
      "6300 0.0008756140596233308\n",
      "6400 0.0007871738052926958\n",
      "6500 0.0007142180693335831\n",
      "6600 0.0006531171966344118\n",
      "6700 0.0006012236699461937\n",
      "6800 0.0005566338077187538\n",
      "6900 0.0005179332802072167\n",
      "7000 0.0004840239998884499\n",
      "7100 0.0004541593953035772\n",
      "7200 0.00042756658513098955\n",
      "7300 0.0004037998151034117\n",
      "7400 0.00038246516487561166\n",
      "7500 0.0003631176077760756\n",
      "7600 0.0003456218109931797\n",
      "7700 0.0003296579816378653\n",
      "7800 0.0003149986150674522\n",
      "7900 0.0003015661786776036\n",
      "8000 0.0002891939366236329\n",
      "8100 0.0002777304034680128\n",
      "8200 0.00026716123102232814\n",
      "8300 0.0002572931698523462\n",
      "8400 0.00024810456670820713\n",
      "8500 0.00023950469039846212\n",
      "8600 0.00023149637854658067\n",
      "8700 0.00022396622807718813\n",
      "8800 0.00021689220739062876\n",
      "8900 0.00021022635337430984\n",
      "9000 0.00020395127648953348\n",
      "9100 0.00019802212773356587\n",
      "9200 0.00019239621178712696\n",
      "9300 0.0001870910928118974\n",
      "9400 0.00018206586537417024\n",
      "9500 0.00017728163220454007\n",
      "9600 0.0001727285562083125\n",
      "9700 0.0001684160524746403\n",
      "9800 0.00016430451069027185\n",
      "9900 0.0001603727723704651\n",
      "10000 0.00015663033991586417\n"
     ]
    }
   ],
   "source": [
    "# 다층 퍼셉트론 구현\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    \n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
    "\n",
    "model = nn.Sequential(\n",
    "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
    "          nn.Sigmoid()\n",
    "          ).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for epoch in range(10001):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501ec87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[1.11750436e-04]\n",
      " [9.99828696e-01]\n",
      " [9.99842167e-01]\n",
      " [1.85394136e-04]]\n",
      "예측값(Predicted):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "source": [
    "# 예측값 확인\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.cpu().numpy())\n",
    "    print('예측값(Predicted): ', predicted.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b1f9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 모델 정의: 순차적인 레이어 구조\u001b[39;00m\n\u001b[32m      8\u001b[39m model = nn.Sequential(\n\u001b[32m      9\u001b[39m     nn.Linear(\u001b[32m64\u001b[39m, \u001b[32m32\u001b[39m), \u001b[38;5;66;03m# 입력층: 64, 첫 번째 은닉층: 32\u001b[39;00m\n\u001b[32m     10\u001b[39m     nn.ReLU(),         \u001b[38;5;66;03m# 활성화 함수: ReLU\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     nn.Linear(\u001b[32m16\u001b[39m, \u001b[32m10\u001b[39m)  \u001b[38;5;66;03m# 두 번째 은닉층: 16, 출력층: 10 (클래스의 개수)\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m X = torch.tensor(\u001b[43mX\u001b[49m, dtype=torch.float32)\n\u001b[32m     17\u001b[39m Y = torch.tensor(Y, dtype=torch.int64)\n\u001b[32m     19\u001b[39m loss_fn = nn.CrossEntropyLoss()  \u001b[38;5;66;03m# 다중 클래스 분류를 위한 손실 함수\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# 숫자 필기 데이터 분류\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # 시각화를 위한 맷플롯립\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "digits = load_digits() # 1,979개의 이미지 데이터 로드\n",
    "\n",
    "X = digits.data # 이미지. 즉, 특성 행렬\n",
    "Y = digits.target # 각 이미지에 대한 레이블\n",
    "\n",
    "# 모델 정의: 순차적인 레이어 구조\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 32), # 입력층: 64, 첫 번째 은닉층: 32\n",
    "    nn.ReLU(),         # 활성화 함수: ReLU\n",
    "    nn.Linear(32, 16), # 첫 번째 은닉층: 32, 두 번째 은닉층: 16\n",
    "    nn.ReLU(),         # 활성화 함수: ReLU\n",
    "    nn.Linear(16, 10)  # 두 번째 은닉층: 16, 출력층: 10 (클래스의 개수)\n",
    ")\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.int64)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()  # 다중 클래스 분류를 위한 손실 함수\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()          # 기울기 초기화\n",
    "    y_pred = model(X)            # 순전파\n",
    "    loss = loss_fn(y_pred, Y)    # 손실 계산\n",
    "    loss.backward()               # 역전파 수행\n",
    "    optimizer.step()              # 가중치 업데이트\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "        \n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 분류\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "X = mnist.data / 255  # 0-255값을 [0,1] 구간으로 정규화\n",
    "y = mnist.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)\n",
    "\n",
    "# 텐서로 변환\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# TensorDataset 객체 생성\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader 객체 생성\n",
    "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)\n",
    "\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(28*28*1, 100))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(100, 100))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(100, 10))\n",
    "\n",
    "# 오차함수 선택\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 가중치를 학습하기 위한 최적화 기법 선택\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 총 3번의 에포크 동안 모델 학습\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for data, targets in loader_train:\n",
    "    optimizer.zero_grad()      # 옵티마이저의 기울기 초기화\n",
    "    y_pred = model(data)          # 순전파 연산으로 예측값 계산\n",
    "    loss = loss_fn(y_pred, targets)  # 손실 함수로 비용 계산\n",
    "    loss.backward()            # 역전파 연산으로 기울기 계산\n",
    "    optimizer.step()           # 옵티마이저를 통해 파라미터 업데이트\n",
    "\n",
    "  print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch + 1, 3, loss.item()))\n",
    "\n",
    "model.eval()  # 신경망을 추론 모드로 전환\n",
    "correct = 0\n",
    "\n",
    "# 데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
    "with torch.no_grad():  # 추론 과정에는 미분이 필요없음\n",
    "    for data, targets in loader_test:\n",
    "\n",
    "        outputs = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "\n",
    "        # 추론 계산\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "        correct += predicted.eq(targets.data.view_as(predicted)).sum()  # 정답과 일치한 경우 정답 카운트를 증가\n",
    "\n",
    "# 정확도 출력\n",
    "data_num = len(loader_test.dataset)  # 데이터 총 건수\n",
    "print('\\n테스트 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "\n",
    "index = 2018\n",
    "\n",
    "model.eval()  # 신경망을 추론 모드로 전환\n",
    "data = X_test[index]\n",
    "output = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "_, predicted = torch.max(output.data, 0)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "\n",
    "print(\"예측 결과 : {}\".format(predicted))\n",
    "\n",
    "X_test_show = (X_test[index]).numpy()\n",
    "plt.imshow(X_test_show.reshape(28, 28), cmap='gray')\n",
    "print(\"이 이미지 데이터의 정답 레이블은 {:.0f}입니다\".format(y_test[index]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
